{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_Text_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO0T_WOYgFLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2K2iUdzihXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import transformers\n",
        "import torch.nn as nn\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch\n",
        "import os,json\n",
        "import pandas as pd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXwq6ZOgkIhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token = {\"username\":\"vinaybhupalam\",\"key\":\"5c27e8b73e30502d96da3d5b41a37fed\"}\n",
        "if not os.path.exists('/root/.kaggle'):\n",
        "\n",
        "  with open('/root/.kaggle/kaggle.json', 'w+') as file:\n",
        "    \n",
        "    json.dump(token, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E5aO3XEkKyF",
        "colab_type": "code",
        "outputId": "55ca6a04-0f7a-4704-a167-70c0461dd479",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "imdb-dataset-of-50k-movie-reviews.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAzA5AHsmUhT",
        "colab_type": "code",
        "outputId": "c3572fb8-9641-4347-86f7-9138ce6ff158",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!unzip imdb-dataset-of-50k-movie-reviews.zip "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  imdb-dataset-of-50k-movie-reviews.zip\n",
            "replace IMDB Dataset.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-l6VgReh-vl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import transformers\n",
        "MAX_LEN = 512\n",
        "TRAIN_BATCH_SIZE = 8\n",
        "VALID_BATCH_SIZE = 8\n",
        "EPOCHS = 10\n",
        "MODEL_PATH = \"model.bin\"\n",
        "TRAINING_FILE = \"IMDB Dataset.csv\"\n",
        "TOKENIZER = transformers.BertTokenizer.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    do_lower_case=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kv1m_vQiInM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BERTDataset:\n",
        "    def __init__(self, review, target):\n",
        "        self.review = review\n",
        "        self.target = target\n",
        "        self.tokenizer = TOKENIZER\n",
        "        self.max_len = MAX_LEN\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.review)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        review = str(self.review[item])\n",
        "        review = \" \".join(review.split())\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            review,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True\n",
        "        )\n",
        "\n",
        "        ids = inputs[\"input_ids\"]\n",
        "        mask = inputs[\"attention_mask\"]\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "        x = torch.tensor(self.target[item], dtype=torch.float, device=torch.device(\"cuda\"))\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long, device=torch.device(\"cuda\")),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long, device=torch.device(\"cuda\")),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long, device=torch.device(\"cuda\")),\n",
        "            'targets' : torch.tensor(self.target[item], dtype=torch.float, device=torch.device(\"cuda\"))\n",
        "        }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7YtqHB5icQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class BERTBaseUncased(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTBaseUncased, self).__init__()\n",
        "        self.bert = transformers.BertModel.from_pretrained(os.getcwd())\n",
        "        self.bert_drop = nn.Dropout(0.3)\n",
        "        self.out = nn.Linear(768, 1)\n",
        "    \n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        _, o2 = self.bert(\n",
        "            ids, \n",
        "            attention_mask=mask,\n",
        "            token_type_ids=token_type_ids\n",
        "        )\n",
        "        bo = self.bert_drop(o2)\n",
        "        output = self.out(bo)        \n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjTyCrCMip8K",
        "colab_type": "code",
        "outputId": "5fc97f46-458e-4c92-db48-7ff0c1cfb22a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XYPoQXZjT3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def loss_fn(outputs, targets):\n",
        "    return nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n",
        "\n",
        "\n",
        "def train_fn(data_loader, model, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "\n",
        "    for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
        "        ids = d[\"ids\"]\n",
        "        token_type_ids = d[\"token_type_ids\"]\n",
        "        mask = d[\"mask\"]\n",
        "        targets = d[\"targets\"]\n",
        "\n",
        "        ids = ids.to(device, dtype=torch.long)\n",
        "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "        mask = mask.to(device, dtype=torch.long)\n",
        "        targets = targets.to(device, dtype=torch.float)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(\n",
        "            ids=ids,\n",
        "            mask=mask,\n",
        "            token_type_ids=token_type_ids\n",
        "        )\n",
        "\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "\n",
        "def eval_fn(data_loader, model, device):\n",
        "    model.eval()\n",
        "    fin_targets = []\n",
        "    fin_outputs = []\n",
        "    with torch.no_grad():\n",
        "        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
        "            ids = d[\"ids\"]\n",
        "            token_type_ids = d[\"token_type_ids\"]\n",
        "            mask = d[\"mask\"]\n",
        "            targets = d[\"targets\"]\n",
        "\n",
        "            ids = ids.to(device, dtype=torch.long)\n",
        "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "            mask = mask.to(device, dtype=torch.long)\n",
        "            targets = targets.to(device, dtype=torch.float)\n",
        "            print(\"Eval fuction target datatype\")\n",
        "            print(targets.device)\n",
        "            outputs = model(\n",
        "                ids=ids,\n",
        "                mask=mask,\n",
        "                token_type_ids=token_type_ids\n",
        "            )\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs, fin_targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okbLyURKLUFn",
        "colab_type": "text"
      },
      "source": [
        "Read the dataset and create train and validation data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8jCKxQ1jY9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "dfx = pd.read_csv(TRAINING_FILE).fillna(\"none\")\n",
        "dfx.sentiment = dfx.sentiment.apply(\n",
        "    lambda x: 1 if x == \"positive\" else 0\n",
        ")\n",
        "\n",
        "df_train, df_valid = model_selection.train_test_split(\n",
        "    dfx[0:10000],\n",
        "    test_size=0.1,\n",
        "    random_state=42,\n",
        "    stratify=dfx[0:10000].sentiment.values\n",
        ")\n",
        "\n",
        "df_train = df_train.reset_index(drop=True)\n",
        "df_valid = df_valid.reset_index(drop=True)\n",
        "\n",
        "\n",
        "train_dataset = BERTDataset(\n",
        "    review=df_train.review.values,\n",
        "    target=df_train.sentiment.values\n",
        ")\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "valid_dataset = BERTDataset(\n",
        "    review=df_valid.review.values,\n",
        "    target=df_valid.sentiment.values\n",
        ")\n",
        "\n",
        "valid_data_loader = torch.utils.data.DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size=VALID_BATCH_SIZE,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "print(device)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6SADm_knYAj",
        "colab_type": "code",
        "outputId": "7baf518f-17a9-486f-a6de-576d112acadb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXUCeUJkoejU",
        "colab_type": "code",
        "outputId": "a08350d3-bf65-423c-9e2c-42e1ffa7b9e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My\\ Drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDHAaP33rz_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gLoDL8FsIXu",
        "colab_type": "code",
        "outputId": "41e718e8-efe1-4ab3-e77d-fd73125207f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jN320JBLH1L",
        "colab_type": "text"
      },
      "source": [
        "Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2JvOwpvnYjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BERTBaseUncased()\n",
        "model.to(device)\n",
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "optimizer_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
        "]\n",
        "\n",
        "num_train_steps = int(len(df_train) / TRAIN_BATCH_SIZE * EPOCHS)\n",
        "optimizer = AdamW(optimizer_parameters, lr=3e-5)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_train_steps\n",
        ")\n",
        "\n",
        "#model = nn.DataParallel(model)\n",
        "import numpy as np\n",
        "best_accuracy = 0\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"Epoch {} \" .format(epoch))\n",
        "    train_fn(train_data_loader, model, optimizer, device, scheduler)\n",
        "    outputs, targets = eval_fn(valid_data_loader, model, device)\n",
        "    outputs = np.array(outputs) >= 0.5\n",
        "    accuracy = metrics.accuracy_score(targets, outputs)\n",
        "    print(f\"Accuracy Score = {accuracy}\")\n",
        "    if accuracy > best_accuracy:\n",
        "        torch.save(model.state_dict(), \"model.bin\")\n",
        "        best_accuracy = accuracy\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bzQNZNgIvlD",
        "colab_type": "text"
      },
      "source": [
        "Evaluate the model with the Test Set of 5000 datapoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wUr6JOzr_4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test = dfx[10000:15000].reset_index(drop=True)\n",
        "test_dataset = BERTDataset(\n",
        "    review=df_test.review.values,\n",
        "    target=df_test.sentiment.values\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    num_workers=0\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2ka0GpXJgy0",
        "colab_type": "code",
        "outputId": "76098de5-3aee-4232-92f2-bddf2b3babee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "MODEL = BERTBaseUncased()    \n",
        "MODEL.load_state_dict(torch.load(\"model.bin\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWfxjz5bH3lC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs, targets = eval_fn(valid_data_loader, model, device)\n",
        "outputs = np.array(outputs) >= 0.5\n",
        "accuracy = metrics.accuracy_score(targets, outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVr8kSUhKnMJ",
        "colab_type": "code",
        "outputId": "4ba6d9c0-afb3-435c-cb4a-60fac519999c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f\"Accuracy Score = {accuracy}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score = 0.889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ujk2ZkdrKml7",
        "colab_type": "code",
        "outputId": "8ed3335a-2283-47cd-e7aa-e866c0e7f0a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(targets, outputs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      0.80      0.88       497\n",
            "         1.0       0.83      0.98      0.90       503\n",
            "\n",
            "    accuracy                           0.89      1000\n",
            "   macro avg       0.90      0.89      0.89      1000\n",
            "weighted avg       0.90      0.89      0.89      1000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}